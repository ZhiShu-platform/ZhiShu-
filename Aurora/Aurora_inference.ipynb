{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74757b82",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional\n",
    "\n",
    "# 忽略NumPy DeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"numpy.core\")\n",
    "\n",
    "# 确保安装必要的依赖库\n",
    "def install_required_packages():\n",
    "    required_packages = ['netCDF4', 'h5netcdf', 'scipy']\n",
    "    for pkg in required_packages:\n",
    "        try:\n",
    "            __import__(pkg)\n",
    "        except ImportError:\n",
    "            print(f\"安装缺失的依赖库: {pkg}\")\n",
    "            subprocess.check_call(\n",
    "                [sys.executable, \"-m\", \"pip\", \"install\", pkg],\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                stderr=subprocess.STDOUT\n",
    "            )\n",
    "\n",
    "# 加载表面变量数据（确保纬度严格递减且为模型兼容维度）\n",
    "def load_surface_data(file_path: str) -> Tuple[Dict[str, torch.Tensor], xr.Dataset]:\n",
    "    try:\n",
    "        engines = ['netcdf4', 'h5netcdf', 'scipy']\n",
    "        ds = None\n",
    "        for engine in engines:\n",
    "            try:\n",
    "                ds = xr.open_dataset(file_path, engine=engine)\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        if ds is None:\n",
    "            raise RuntimeError(\"无法加载表面变量数据\")\n",
    "        \n",
    "        print(f\"成功加载表面变量数据，包含变量: {list(ds.variables.keys())}\")\n",
    "        \n",
    "        # 确保纬度严格递减\n",
    "        if not np.all(np.diff(ds.latitude.values) < 0):\n",
    "            print(\"表面数据纬度不是严格递减，正在翻转...\")\n",
    "            ds = ds.reindex(latitude=ds.latitude[::-1])\n",
    "        \n",
    "\n",
    "        if len(ds.latitude) == 721:\n",
    "            ds = ds.isel(latitude=slice(0, 720))\n",
    "        \n",
    "        # 变量映射（原始变量名 -> 模型所需变量名）\n",
    "        var_mapping = {\n",
    "            'u10': '10u',\n",
    "            'v10': '10v',\n",
    "            't2m': '2t',\n",
    "            'msl': 'msl'\n",
    "        }\n",
    "        \n",
    "        # 提取并预处理变量\n",
    "        surf_vars = {}\n",
    "        for raw_var, model_var in var_mapping.items():\n",
    "            if raw_var not in ds.variables:\n",
    "                raise ValueError(f\"表面数据缺少必要变量: {raw_var}\")\n",
    "            \n",
    "            data = ds[raw_var].values\n",
    "            if data.ndim < 3:\n",
    "                raise ValueError(f\"表面变量 {raw_var} 维度不正确（期望至少3维，实际{data.ndim}维）\")\n",
    "            \n",
    "            # 处理时间维度（取最后两个时间步）\n",
    "            if data.shape[0] >= 2:\n",
    "                data = data[-2:, ...]  # 形状: (time, lat, lon)\n",
    "            else:\n",
    "                data = np.repeat(data, 2, axis=0)[:2, ...]\n",
    "            \n",
    "            # 转换为张量 (b, t, h, w)\n",
    "            tensor = torch.from_numpy(data[None, ...].copy())\n",
    "            surf_vars[model_var] = tensor\n",
    "            print(f\"表面变量 {model_var} 维度: {tensor.shape}\")\n",
    "        \n",
    "        return surf_vars, ds\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"加载表面变量数据失败: {str(e)}\")\n",
    "\n",
    "# 加载高空变量数据（处理纬度顺序和压力维度）\n",
    "def load_atmospheric_data(file_path: str) -> Tuple[Dict[str, torch.Tensor], Tuple[int, ...]]:\n",
    "    install_required_packages()\n",
    "    \n",
    "    engines = ['netcdf4', 'h5netcdf', 'scipy']\n",
    "    air_ds = None\n",
    "    \n",
    "    for engine in engines:\n",
    "        try:\n",
    "            print(f\"尝试使用{engine}引擎加载高空数据...\")\n",
    "            if engine == 'h5netcdf':\n",
    "                air_ds = xr.open_dataset(file_path, engine=engine, invalid_netcdf=True)\n",
    "            else:\n",
    "                air_ds = xr.open_dataset(file_path, engine=engine)\n",
    "            print(f\"成功使用{engine}引擎加载高空数据\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"使用{engine}引擎加载失败: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if air_ds is None:\n",
    "        raise RuntimeError(\"所有可用引擎都无法加载高空数据\")\n",
    "    \n",
    "    print(f\"高空变量数据包含变量: {list(air_ds.variables.keys())}\")\n",
    "    \n",
    "    # 处理压力水平维度\n",
    "    required_levels = (50, 100, 150, 200, 250, 300, 400, 500, 600, 700, 850, 925, 1000)\n",
    "    if 'pressure_level' in air_ds.dims:\n",
    "        air_ds = air_ds.rename({'pressure_level': 'level'})\n",
    "    elif 'level' not in air_ds.dims:\n",
    "        level_dims = [dim for dim in air_ds.dims if 'level' in dim]\n",
    "        if not level_dims:\n",
    "            raise ValueError(\"高空数据缺少压力水平维度\")\n",
    "        air_ds = air_ds.rename({level_dims[0]: 'level'})\n",
    "    \n",
    "    # 对齐压力水平\n",
    "    ds_levels = set(air_ds.level.values.astype(int))\n",
    "    valid_levels = [l for l in required_levels if l in ds_levels]\n",
    "    if not valid_levels:\n",
    "        raise ValueError(\"没有找到有效的压力水平\")\n",
    "    air_ds = air_ds.sel(level=valid_levels)\n",
    "    \n",
    "    # 确保纬度严格递减且与表面数据维度一致\n",
    "    if not np.all(np.diff(air_ds.latitude.values) < 0):\n",
    "        print(\"高空数据纬度不是严格递减，正在翻转...\")\n",
    "        air_ds = air_ds.reindex(latitude=air_ds.latitude[::-1])\n",
    "    \n",
    "\n",
    "    if len(air_ds.latitude) == 721:\n",
    "        air_ds = air_ds.isel(latitude=slice(0, 720))\n",
    "    \n",
    "    # 预处理高空变量\n",
    "    atmos_vars = {}\n",
    "    required_atmos_vars = ['t', 'u', 'v', 'q', 'z']\n",
    "    for var in required_atmos_vars:\n",
    "        if var not in air_ds.variables:\n",
    "            raise ValueError(f\"高空数据缺少必要变量: {var}\")\n",
    "        \n",
    "        data = air_ds[var].values  # 维度: (time, level, lat, lon)\n",
    "        if data.ndim < 4:\n",
    "            raise ValueError(f\"高空变量 {var} 维度不正确（期望至少4维，实际{data.ndim}维）\")\n",
    "        \n",
    "        # 处理时间维度\n",
    "        if data.shape[0] >= 2:\n",
    "            data = data[-2:, ...]\n",
    "        else:\n",
    "            data = np.repeat(data, 2, axis=0)[:2, ...]\n",
    "        \n",
    "        # 转换为张量 (b, t, c, h, w)\n",
    "        tensor = torch.from_numpy(data[None, ...].copy())\n",
    "        atmos_vars[var] = tensor\n",
    "        print(f\"高空变量 {var} 维度: {tensor.shape}\")\n",
    "    \n",
    "    return atmos_vars, tuple(valid_levels)\n",
    "\n",
    "# 加载静态变量（确保与目标经纬度维度严格匹配）\n",
    "def load_static_data(file_path: str, target_lat: np.ndarray, target_lon: np.ndarray) -> Dict[str, torch.Tensor]:\n",
    "    try:\n",
    "        if not Path(file_path).exists():\n",
    "            raise FileNotFoundError(f\"静态变量文件不存在: {file_path}\")\n",
    "        \n",
    "        with open(file_path, 'rb') as f:\n",
    "            static_data = pickle.load(f)\n",
    "        \n",
    "        required_static_vars = ['lsm', 'slt', 'z']\n",
    "        missing_vars = [var for var in required_static_vars if var not in static_data]\n",
    "        if missing_vars:\n",
    "            raise ValueError(f\"静态数据缺少必要变量: {missing_vars}\")\n",
    "        \n",
    "        # 目标维度（已同步为720）\n",
    "        target_lat_len = len(target_lat)\n",
    "        target_lon_len = len(target_lon)\n",
    "        target_shape = (target_lat_len, target_lon_len)\n",
    "        print(f\"目标静态变量维度: {target_shape}\")\n",
    "        \n",
    "        # 处理静态变量\n",
    "        static_vars = {}\n",
    "        for var in required_static_vars:\n",
    "            data = static_data[var]\n",
    "            current_shape = data.shape[-2:]\n",
    "            \n",
    "            if current_shape != target_shape:\n",
    "                from scipy.ndimage import zoom\n",
    "                # 计算精确缩放因子\n",
    "                zoom_factor = (\n",
    "                    target_lat_len / current_shape[0],\n",
    "                    target_lon_len / current_shape[1]\n",
    "                )\n",
    "                # 缩放并强制维度匹配目标\n",
    "                data_zoomed = zoom(data, zoom_factor, order=1)  # 双线性插值\n",
    "                data_zoomed = data_zoomed[:target_lat_len, :target_lon_len]  # 精确裁剪\n",
    "                data = data_zoomed\n",
    "            \n",
    "            tensor = torch.from_numpy(data.copy())\n",
    "            static_vars[var] = tensor\n",
    "            print(f\"静态变量 {var} 维度: {tensor.shape}\")\n",
    "        \n",
    "        return static_vars\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"加载静态变量数据失败: {str(e)}\")\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    # 配置文件路径,此处替换为自己的路径\n",
    "    surface_file_path = \"\"\n",
    "    atmospheric_file_path = \"\"\n",
    "    static_file_path = \"\"\n",
    "    model_checkpoint_path = \"\"\n",
    "    output_dir = Path(\"\")\n",
    "    \n",
    "    # 确保输出目录存在，如果不存在则创建\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"已创建输出目录: {output_dir}\")\n",
    "    else:\n",
    "        print(f\"输出目录已存在: {output_dir}\")\n",
    "    \n",
    "    try:\n",
    "        # 加载数据\n",
    "        surf_vars, surf_ds = load_surface_data(surface_file_path)\n",
    "        atmos_vars, atmos_levels = load_atmospheric_data(atmospheric_file_path)\n",
    "        \n",
    "        # 提取目标经纬度（已同步为720）\n",
    "        target_lat = surf_ds.latitude.values\n",
    "        target_lon = surf_ds.longitude.values\n",
    "        lat_len = len(target_lat)\n",
    "        lon_len = len(target_lon)\n",
    "        print(f\"目标经纬度长度: 纬度={lat_len}, 经度={lon_len}\")\n",
    "        \n",
    "        # 加载静态变量（确保维度匹配）\n",
    "        static_vars = load_static_data(\n",
    "            file_path=static_file_path,\n",
    "            target_lat=target_lat,\n",
    "            target_lon=target_lon\n",
    "        )\n",
    "        \n",
    "        # 校验所有变量的空间维度一致性\n",
    "        for var, tensor in surf_vars.items():\n",
    "            if tensor.shape[-2] != lat_len or tensor.shape[-1] != lon_len:\n",
    "                raise ValueError(f\"表面变量 {var} 空间维度不匹配（期望({lat_len},{lon_len})，实际{tensor.shape[-2:]}）\")\n",
    "        \n",
    "        for var, tensor in atmos_vars.items():\n",
    "            if tensor.shape[-2] != lat_len or tensor.shape[-1] != lon_len:\n",
    "                raise ValueError(f\"高空变量 {var} 空间维度不匹配（期望({lat_len},{lon_len})，实际{tensor.shape[-2:]}）\")\n",
    "        \n",
    "        for var, tensor in static_vars.items():\n",
    "            if tensor.shape[-2] != lat_len or tensor.shape[-1] != lon_len:\n",
    "                raise ValueError(f\"静态变量 {var} 空间维度不匹配（期望({lat_len},{lon_len})，实际{tensor.shape[-2:]}）\")\n",
    "        \n",
    "        # 准备输入批次\n",
    "        from aurora import Batch, Metadata\n",
    "        batch = Batch(\n",
    "            surf_vars=surf_vars,\n",
    "            static_vars=static_vars,\n",
    "            atmos_vars=atmos_vars,\n",
    "            metadata=Metadata(\n",
    "                lat=torch.from_numpy(target_lat.copy()),  # 已确保纬度递减且为720\n",
    "                lon=torch.from_numpy(target_lon.copy()),\n",
    "                #-1是有效时间的最后一个时间点，可以修改起始时间，-n表示倒数第n个，有多少个时间点取决于官网下载的数据选择了几天、几个小时。\n",
    "                time=(np.datetime64(surf_ds.valid_time.values[-1]).astype('datetime64[s]').item(),),\n",
    "                #一定注意不要越界：比如一共只有99个时间点，起始时间点就不能是-100。\n",
    "                atmos_levels=atmos_levels\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 加载模型（使用本地checkpoint）\n",
    "        from aurora import AuroraPretrained  # 对应0.25°预训练模型\n",
    "        model = AuroraPretrained()\n",
    "        model.load_checkpoint_local(model_checkpoint_path)\n",
    "        model.eval()  # 设置为评估模式\n",
    "        \n",
    "        # 模型预测\n",
    "        with torch.inference_mode():\n",
    "            prediction = model.forward(batch)\n",
    "        \n",
    "        # 保存预测结果\n",
    "        surf_output_file = output_dir / \"surface.nc\" #文件名称可更改\n",
    "        atmos_output_file = output_dir / \"air.nc\" #文件名称可更改\n",
    "        \n",
    "        # 处理表面变量预测\n",
    "        def process_surf_pred(var):\n",
    "            pred_tensor = prediction.surf_vars[var]\n",
    "            # 形状应为 (b, t, h, w)，挤压为 (h, w)\n",
    "            pred_np = pred_tensor.squeeze().numpy()\n",
    "            # 确保空间维度匹配\n",
    "            if pred_np.shape[0] != lat_len or pred_np.shape[1] != lon_len:\n",
    "                # 若不匹配，使用插值调整\n",
    "                from scipy.ndimage import zoom\n",
    "                zoom_factor = (\n",
    "                    lat_len / pred_np.shape[0],\n",
    "                    lon_len / pred_np.shape[1]\n",
    "                )\n",
    "                pred_np = zoom(pred_np, zoom_factor, order=1)\n",
    "                print(f\"表面预测变量 {var} 维度不匹配，已插值为({lat_len},{lon_len})\")\n",
    "            # 添加时间维度 (1, h, w)\n",
    "            return np.expand_dims(pred_np, axis=0)\n",
    "        \n",
    "        pred_2t = process_surf_pred(\"2t\")\n",
    "        pred_10u = process_surf_pred(\"10u\")\n",
    "        pred_10v = process_surf_pred(\"10v\")\n",
    "        pred_msl = process_surf_pred(\"msl\")\n",
    "        \n",
    "        # 构建表面变量输出数据集\n",
    "        surf_pred_ds = xr.Dataset(\n",
    "            data_vars={\n",
    "                \"2t_pred\": ([\"time\", \"latitude\", \"longitude\"], pred_2t),\n",
    "                \"10u_pred\": ([\"time\", \"latitude\", \"longitude\"], pred_10u),\n",
    "                \"10v_pred\": ([\"time\", \"latitude\", \"longitude\"], pred_10v),\n",
    "                \"msl_pred\": ([\"time\", \"latitude\", \"longitude\"], pred_msl)\n",
    "            },\n",
    "            coords={\n",
    "                #跟上面对应，surf_ds.valid_time.values[-1]：这里与上面选择的起始时间相同，是倒数第一个时间点\n",
    "                #np.timedelta64(6, 'h')]，这里的6表示推测的是往后6h的气象数据，比如23h到5h，可以修改\n",
    "                #但模型的有效预测能力受限于其设计的短期范围，超出后准确性会大幅下降，并非 “任意时间都能得到可靠结果”。\n",
    "                \"time\": [np.datetime64(surf_ds.valid_time.values[-1]) + np.timedelta64(6, 'h')],\n",
    "                \"latitude\": target_lat,\n",
    "                \"longitude\": target_lon\n",
    "            }\n",
    "        )\n",
    "        surf_pred_ds.to_netcdf(surf_output_file)\n",
    "        print(f\"表面变量预测结果已保存至: {surf_output_file}\")\n",
    "        \n",
    "        # 处理高空变量预测\n",
    "        def process_atmos_pred(var):\n",
    "            pred_tensor = prediction.atmos_vars[var]\n",
    "            # 形状应为 (b, t, c, h, w)，挤压为 (c, h, w)\n",
    "            pred_np = pred_tensor.squeeze().numpy()\n",
    "            # 确保空间维度匹配\n",
    "            if pred_np.shape[-2] != lat_len or pred_np.shape[-1] != lon_len:\n",
    "                from scipy.ndimage import zoom\n",
    "                # 计算缩放因子（保留压力水平维度）\n",
    "                zoom_factor = (1,  # 压力水平维度不缩放\n",
    "                               lat_len / pred_np.shape[-2],\n",
    "                               lon_len / pred_np.shape[-1])\n",
    "                pred_np = zoom(pred_np, zoom_factor, order=1)\n",
    "                print(f\"高空预测变量 {var} 维度不匹配，已插值为({pred_np.shape})\")\n",
    "            # 添加时间维度 (1, c, h, w)\n",
    "            return np.expand_dims(pred_np, axis=0)\n",
    "        \n",
    "        # 提取所有高空变量预测\n",
    "        atmos_vars_list = ['t', 'u', 'v', 'q', 'z']\n",
    "        atmos_preds = {var: process_atmos_pred(var) for var in atmos_vars_list}\n",
    "        \n",
    "        # 获取预测的压力水平并转换为numpy数组（关键修复）\n",
    "        pred_levels = np.array(prediction.metadata.atmos_levels, dtype=int)\n",
    "        \n",
    "        # 构建高空变量输出数据集\n",
    "        atmos_pred_ds = xr.Dataset(\n",
    "            data_vars={\n",
    "                f\"{var}_pred\": ([\"time\", \"level\", \"latitude\", \"longitude\"], atmos_preds[var])\n",
    "                for var in atmos_vars_list\n",
    "            },\n",
    "            coords={\n",
    "                #跟上面对应，surf_ds.valid_time.values[-1]：这里与上面选择的起始时间相同，是倒数第一个时间点\n",
    "                #np.timedelta64(6, 'h')]，这里的6表示推测的是往后6h的气象数据，比如23h到5h，可以修改\n",
    "                #但模型的有效预测能力受限于其设计的短期范围，超出后准确性会大幅下降，并非 “任意时间都能得到可靠结果”。\n",
    "                \"time\": [np.datetime64(surf_ds.valid_time.values[-1]) + np.timedelta64(6, 'h')],\n",
    "                \"level\": pred_levels,  # 使用numpy数组而非元组\n",
    "                \"latitude\": target_lat,\n",
    "                \"longitude\": target_lon\n",
    "            }\n",
    "        )\n",
    "        atmos_pred_ds.to_netcdf(atmos_output_file)\n",
    "        print(f\"高空变量预测结果已保存至: {atmos_output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"执行出错: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
